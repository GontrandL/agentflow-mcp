{
  "meta": {
    "project": "APC Phase 2: Persistent Memory & Session Continuity",
    "strategy": "Parallel delegation with Taskmaster + AgentFlow",
    "workers": 4,
    "estimated_duration": "60-90 minutes total",
    "cost_estimate": "$0.40 (vs $120 direct Claude)",
    "savings": "99.67%"
  },
  "project_context": {
    "existing_files": {
      "core": [
        "agentflow/core/project_scanner.py",
        "agentflow/core/context_generator.py"
      ],
      "integration": [
        "agentflow/integration/apc_agentflow_bridge.py",
        "agentflow/integration/a2a_protocol.py",
        "agentflow/integration/apc_a2a_adapter.py"
      ]
    },
    "patterns_to_follow": {
      "manager_classes": "Follow pattern: class {Name}Manager with public methods",
      "location": "agentflow/core/ for core components",
      "imports": "from pathlib import Path, import json, from datetime import datetime",
      "dataclasses": "Use @dataclass for data structures",
      "type_hints": "100% type hints required",
      "docstrings": "Google style docstrings for all classes/methods"
    },
    "research_validation": {
      "memory_architecture": "Tier 1: JSON files (< 1ms, < $0.001/month)",
      "benchmarks": "< 30s recovery, < 2KB checkpoints, < 1ms write",
      "sources": "4 AI research consensus (Claude, Perplexity 150 citations, Gemini/ChatGPT, DeepSeek)"
    }
  },
  "tasks": [
    {
      "task_id": "phase2-worker-1",
      "name": "SessionHistoryManager",
      "priority": "critical",
      "estimated_minutes": 15,
      "description": "[MISSION]: Implement SessionHistoryManager - Track all worker activities via A2A events\n\n## Context\n- Project: APC Phase 2 - Persistent Memory\n- Location: agentflow/core/session_history.py\n- Technology: Python 3.11, dataclasses, JSON, pathlib\n- Patterns: Follow existing Manager classes (ContextGenerator, ProjectScanner)\n\n## Requirements\n\n**Research Validation**:\n- Based on Perplexity research (150 citations): \"Append-only logs for traceability, auditing, self-improvement\"\n- Gemini/ChatGPT: \"Track agent steps with timestamps for meta-learning\"\n- Claude: \"Session log mining enables continuous improvement\"\n- **Benchmark**: < 1ms write overhead (JSON)\n\n**Core Functionality**:\n1. SessionEvent dataclass:\n   - timestamp: str (ISO format)\n   - event_type: str (\"query\", \"response\", \"task_completed\", \"file_modified\")\n   - agent_id: str (worker ID)\n   - payload: Dict[str, Any]\n   - context: Optional[Dict[str, Any]]\n\n2. SessionHistoryManager class:\n   - __init__(self, apc_root: Path)\n   - record_a2a_event(self, event: SessionEvent) -> None\n   - end_session(self) -> Path  # Archives to YYYY-MM-DD.json\n   - get_recent_events(self, limit: int = 100, event_type: Optional[str] = None) -> List[SessionEvent]\n   - _load_current_session(self) -> None\n   - _save_current_session(self) -> None  # < 1ms write\n\n**Directory Structure**:\n```\n.apc/\n└── sessions/\n    ├── current_session.json (active, < 50KB typically)\n    ├── 2025-10-14.json (today's archive)\n    └── 2025-10-13.json (yesterday)\n```\n\n**Integration Points**:\n- Called by: apc_a2a_adapter.py in handle_message()\n- Used by: KnowledgeBase for pattern learning\n- Data flow: A2A message → SessionEvent → JSON file\n\n## Deliverables\n\nOutput to: `agentflow/core/session_history.py`\n\nInclude:\n1. Complete SessionEvent dataclass with type hints\n2. Complete SessionHistoryManager class\n3. Google-style docstrings for all public methods\n4. Type hints: 100%\n5. Error handling for file I/O\n6. Idempotent operations (can be called multiple times)\n\n## Output Format\n\n**File Structure**:\n```python\n# agentflow/core/session_history.py\n\"\"\"Session history tracking for APC Phase 2.\n\nBased on research consensus:\n- Append-only logs (Perplexity 150 citations)\n- JSON storage (< 1ms write)\n- Meta-learning data source (Gemini/ChatGPT)\n\"\"\"\n\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\n\n# [Implementation here]\n```\n\n## Success Criteria\n\n- ✅ SessionEvent dataclass complete\n- ✅ SessionHistoryManager class complete\n- ✅ record_a2a_event() < 1ms overhead\n- ✅ end_session() archives correctly\n- ✅ get_recent_events() filtering works\n- ✅ 100% type hints\n- ✅ Google-style docstrings\n- ✅ No placeholders or TODOs\n- ✅ Idempotent operations\n- ✅ Error handling for edge cases\n\n## Code Quality Requirements\n\n- Follow PEP 8 style guide\n- Use pathlib.Path (not os.path)\n- Use datetime.now().isoformat() for timestamps\n- Handle FileNotFoundError gracefully\n- Ensure atomic file writes (write to temp, then rename)\n- Keep methods focused (single responsibility)\n- No external dependencies beyond stdlib + typing",
      "dependencies": []
    },
    {
      "task_id": "phase2-worker-2",
      "name": "TaskTracker",
      "priority": "critical",
      "estimated_minutes": 15,
      "description": "[MISSION]: Implement TaskTracker - Persistent task state with TodoWrite integration\n\n## Context\n- Project: APC Phase 2 - Persistent Memory\n- Location: agentflow/core/task_tracker.py\n- Technology: Python 3.11, dataclasses, JSON, pathlib\n- Patterns: Follow SessionHistoryManager structure\n\n## Requirements\n\n**Research Validation**:\n- Perplexity: \"Critical state in JSON files for instant reload\"\n- Claude: \"Task queues in persistent JSON\"\n- Gemini/ChatGPT: \"Idempotent Superstep Checkpointing (ISC)\"\n- **Benchmark**: < 1ms read/write (JSON)\n\n**Core Functionality**:\n1. Task dataclass:\n   - task_id: str\n   - content: str\n   - status: str (\"pending\", \"in_progress\", \"completed\")\n   - priority: str (\"low\", \"medium\", \"high\", \"critical\")\n   - agent_id: Optional[str]\n   - created_at: str (ISO timestamp)\n   - updated_at: str (ISO timestamp)\n   - metadata: Dict[str, Any] (optional)\n\n2. TaskTracker class:\n   - __init__(self, apc_root: Path)\n   - add_task(self, task: Task) -> None  # Idempotent\n   - update_task_status(self, task_id: str, status: str, agent_id: Optional[str] = None) -> None\n   - get_active_tasks(self, status: Optional[str] = None) -> List[Task]\n   - record_task_event_from_a2a(self, message: A2AMessage) -> None  # Integration\n   - _load_active_tasks(self) -> None\n   - _save_active_tasks(self) -> None\n   - _save_task_file(self, task: Task) -> None  # Individual task files\n\n**Directory Structure**:\n```\n.apc/\n└── tasks/\n    ├── active_tasks.json (all tasks, < 20KB)\n    ├── task-001.json (individual task)\n    ├── task-002.json\n    └── task-003.json\n```\n\n**Integration Points**:\n- Called by: apc_a2a_adapter.py for task events\n- TodoWrite integration: Sync with Claude Code TodoWrite\n- A2A message types: \"task_completed\", \"task_started\"\n\n## Deliverables\n\nOutput to: `agentflow/core/task_tracker.py`\n\nInclude:\n1. Complete Task dataclass\n2. Complete TaskTracker class\n3. TodoWrite integration logic\n4. Google-style docstrings\n5. Type hints: 100%\n6. Idempotent operations (ISC pattern)\n7. Error handling\n\n## Output Format\n\n**File Structure**:\n```python\n# agentflow/core/task_tracker.py\n\"\"\"Task tracking for APC Phase 2.\n\nBased on research consensus:\n- JSON storage (< 1ms)\n- Idempotent operations (Gemini/ChatGPT ISC)\n- TodoWrite integration\n\"\"\"\n\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Dict, Any, Optional\nfrom pathlib import Path\nimport json\nfrom datetime import datetime\n\n# [Implementation here]\n```\n\n## Success Criteria\n\n- ✅ Task dataclass complete\n- ✅ TaskTracker class complete\n- ✅ add_task() idempotent\n- ✅ update_task_status() works\n- ✅ get_active_tasks() filtering\n- ✅ record_task_event_from_a2a() integration\n- ✅ Individual task files saved\n- ✅ 100% type hints\n- ✅ Google-style docstrings\n- ✅ No placeholders/TODOs\n- ✅ Error handling\n\n## Code Quality Requirements\n\n- Follow PEP 8\n- Use pathlib.Path\n- ISO timestamps via datetime\n- Atomic file writes\n- Idempotent: Multiple calls same result\n- Handle missing task gracefully\n- Priority sorting (high → low)",
      "dependencies": []
    },
    {
      "task_id": "phase2-worker-3",
      "name": "KnowledgeBase",
      "priority": "high",
      "estimated_minutes": 20,
      "description": "[MISSION]: Implement KnowledgeBase - Store learned patterns and project insights\n\n## Context\n- Project: APC Phase 2 - Persistent Memory\n- Location: agentflow/core/knowledge_base.py\n- Technology: Python 3.11, dataclasses, JSON, pathlib\n- Patterns: Meta-learning from session logs\n\n## Requirements\n\n**Research Validation**:\n- Gemini/ChatGPT: \"Graph DB queries for failure analysis, pattern discovery\"\n- Perplexity: \"Meta-learning from session logs\"\n- Claude: \"Pattern recognition in agent behavior logs\"\n- **Benchmark**: < 100ms pattern matching\n\n**Core Functionality**:\n1. Pattern dataclass:\n   - pattern_id: str\n   - pattern_type: str (\"validation\", \"orchestration\", \"test\", etc.)\n   - description: str\n   - examples: List[str] (file paths)\n   - confidence: float (0.0-1.0)\n   - discovered_at: str (ISO timestamp)\n   - usage_count: int (tracks how often pattern used)\n\n2. ProjectInsight dataclass:\n   - insight_id: str\n   - category: str (\"architecture\", \"naming\", \"testing\")\n   - insight: str\n   - supporting_evidence: List[str]\n   - confidence: float\n   - created_at: str\n\n3. KnowledgeBase class:\n   - __init__(self, apc_root: Path)\n   - learn_pattern_from_session(self, session_events: List[SessionEvent]) -> List[Pattern]\n   - add_pattern(self, pattern: Pattern) -> None  # Idempotent\n   - get_recommendations_for_task(self, task: str) -> List[str]  # Context-aware!\n   - add_insight(self, insight: ProjectInsight) -> None\n   - _discover_validation_pattern(self, event: SessionEvent) -> Optional[Pattern]\n   - _discover_orchestration_pattern(self, event: SessionEvent) -> Optional[Pattern]\n   - _load_knowledge(self) -> None\n   - _save_patterns(self) -> None\n   - _save_insights(self) -> None\n\n**Directory Structure**:\n```\n.apc/\n└── knowledge/\n    ├── patterns.json (discovered patterns)\n    ├── recommendations.json (context-aware recommendations)\n    └── project_insights.json (cumulative learning)\n```\n\n**Pattern Discovery Logic**:\n- Analyze session events (queries from workers)\n- Extract keywords: \"validation\", \"orchestrator\", \"test\"\n- Match to project files (via APC project scanner)\n- Generate recommendations based on patterns\n\n**Integration Points**:\n- Called by: apc_a2a_adapter.py in end_session()\n- Uses: SessionHistoryManager.get_recent_events()\n- Provides: Context-aware recommendations to workers\n\n## Deliverables\n\nOutput to: `agentflow/core/knowledge_base.py`\n\nInclude:\n1. Complete Pattern dataclass\n2. Complete ProjectInsight dataclass\n3. Complete KnowledgeBase class\n4. Pattern discovery logic (validation, orchestration)\n5. get_recommendations_for_task() with smart matching\n6. Google-style docstrings\n7. Type hints: 100%\n8. Meta-learning algorithm (simple but effective)\n\n## Output Format\n\n**File Structure**:\n```python\n# agentflow/core/knowledge_base.py\n\"\"\"Knowledge base for pattern learning (APC Phase 2).\n\nBased on research consensus:\n- Meta-learning (Perplexity ACE)\n- Pattern recognition (Claude)\n- Continuous improvement (Gemini/ChatGPT Kaizen)\n\"\"\"\n\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Dict, Any, Optional\nfrom pathlib import Path\nimport json\nfrom datetime import datetime\n\n# [Implementation here]\n```\n\n## Success Criteria\n\n- ✅ Pattern dataclass complete\n- ✅ ProjectInsight dataclass complete\n- ✅ KnowledgeBase class complete\n- ✅ learn_pattern_from_session() works\n- ✅ Pattern discovery logic implemented\n- ✅ get_recommendations_for_task() smart matching\n- ✅ Confidence tracking (usage_count)\n- ✅ 100% type hints\n- ✅ Google-style docstrings\n- ✅ No placeholders/TODOs\n\n## Code Quality Requirements\n\n- Follow PEP 8\n- Use pathlib.Path\n- Pattern matching: case-insensitive\n- Confidence increases with usage\n- Smart keyword extraction\n- Examples limited to top 2-3\n- Recommendations actionable",
      "dependencies": ["phase2-worker-1"]
    },
    {
      "task_id": "phase2-worker-4",
      "name": "SessionContinuityProtocol",
      "priority": "critical",
      "estimated_minutes": 15,
      "description": "[MISSION]: Implement SessionContinuityProtocol - < 30s recovery between Claude Code sessions\n\n## Context\n- Project: APC Phase 2 - Persistent Memory\n- Location: agentflow/core/session_continuity.py\n- Technology: Python 3.11, dataclasses, JSON, pathlib\n- Patterns: Delta snapshots, minimal checkpoints\n\n## Requirements\n\n**Research Validation**:\n- Perplexity: \"< 2KB recovery instructions, 1-12s delta snapshots (150 citations)\"\n- Claude: \"Session continuity protocol with minimal pickup instructions\"\n- Gemini/ChatGPT: \"Idempotent Superstep Checkpointing\"\n- **Benchmark**: < 30s recovery GUARANTEED\n\n**Core Functionality**:\n1. SessionCheckpoint dataclass:\n   - checkpoint_id: str\n   - timestamp: str (ISO)\n   - last_task: str (brief description)\n   - active_tasks: int (count)\n   - pending_tasks: int (count)\n   - recent_events_summary: str (< 500 words)\n   - project_state_hash: str (quick validation)\n\n2. SessionContinuityProtocol class:\n   - __init__(self, apc_root: Path)\n   - create_checkpoint(self, session_history: SessionHistoryManager, task_tracker: TaskTracker, knowledge_base: KnowledgeBase) -> SessionCheckpoint\n   - resume_session(self) -> Dict[str, Any]  # < 30s guarantee!\n   - _summarize_events(self, events: List[SessionEvent]) -> str  # < 500 words\n   - _compute_state_hash(self) -> str  # Quick MD5 hash\n   - _save_checkpoint(self, checkpoint: SessionCheckpoint) -> None  # < 2KB, < 1ms\n\n**Directory Structure**:\n```\n.apc/\n└── checkpoints/\n    ├── latest.json (< 2KB, instant recovery)\n    ├── checkpoint-001.json (historical)\n    └── checkpoint-002.json\n```\n\n**Checkpoint Content** (< 2KB target):\n```json\n{\n  \"checkpoint_id\": \"ckpt-1728930605\",\n  \"timestamp\": \"2025-10-14T14:10:05Z\",\n  \"last_task\": \"Worker-001 queried validation patterns\",\n  \"active_tasks\": 2,\n  \"pending_tasks\": 5,\n  \"recent_events_summary\": \"Last 5 events: query | response | task_completed...\",\n  \"project_state_hash\": \"a3f2d8c1\"\n}\n```\n\n**Integration Points**:\n- Called by: apc_a2a_adapter.py in end_session()\n- Uses: SessionHistoryManager, TaskTracker, KnowledgeBase\n- Called by: apc_a2a_adapter.py in start_session()\n\n## Deliverables\n\nOutput to: `agentflow/core/session_continuity.py`\n\nInclude:\n1. Complete SessionCheckpoint dataclass\n2. Complete SessionContinuityProtocol class\n3. create_checkpoint() with < 2KB target\n4. resume_session() with < 30s guarantee\n5. Event summarization (< 500 words)\n6. State hash computation (MD5)\n7. Google-style docstrings\n8. Type hints: 100%\n9. Atomic checkpoint writes\n\n## Output Format\n\n**File Structure**:\n```python\n# agentflow/core/session_continuity.py\n\"\"\"Session continuity protocol (APC Phase 2).\n\nBased on research consensus:\n- < 2KB recovery (Perplexity)\n- < 30s guarantee (all 4 sources)\n- Delta snapshots (1-12s)\n- ISC pattern (Gemini/ChatGPT)\n\"\"\"\n\nfrom dataclasses import dataclass, asdict\nfrom typing import Dict, Any, List\nfrom pathlib import Path\nimport json\nfrom datetime import datetime\nimport hashlib\n\n# [Implementation here]\n```\n\n## Success Criteria\n\n- ✅ SessionCheckpoint dataclass complete\n- ✅ SessionContinuityProtocol class complete\n- ✅ create_checkpoint() < 2KB\n- ✅ resume_session() < 30s\n- ✅ Event summarization works\n- ✅ State hash MD5 implemented\n- ✅ Atomic file writes\n- ✅ 100% type hints\n- ✅ Google-style docstrings\n- ✅ No placeholders/TODOs\n\n## Code Quality Requirements\n\n- Follow PEP 8\n- Use pathlib.Path\n- MD5 hash: hashlib.md5().hexdigest()[:8]\n- Checkpoint ID: f\"ckpt-{int(datetime.now().timestamp())}\"\n- Summarization: Last 5 events, brief\n- Atomic: Write to .tmp, rename to .json\n- Error handling: Missing checkpoint OK",
      "dependencies": ["phase2-worker-1", "phase2-worker-2", "phase2-worker-3"]
    }
  ]
}
