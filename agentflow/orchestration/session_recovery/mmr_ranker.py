"""
MMR (Maximal Marginal Relevance) Ranker for SessionContextCurator

This module implements diversity-aware file ranking to prevent redundant
file selection in context packs. Uses Jaccard similarity on path components
to measure diversity.

Generated by: AgentFlow Worker 1 (DeepSeek V3)
Date: 2025-10-14
Cost: $0.15
Duration: 3 minutes
"""

from dataclasses import dataclass
from typing import List, Optional


@dataclass
class FileCandidate:
    """
    Represents a file candidate for context pack inclusion.

    Attributes:
        path: File path (e.g., "tests/auth/test_login.py")
        relevance_score: Relevance to task (0.0-1.0)
        size_tokens: Estimated token size
        section: Optional section identifier
    """
    path: str
    relevance_score: float
    size_tokens: int
    section: Optional[str] = ""

    def __post_init__(self):
        """Validate all attributes on initialization."""
        # Validate path
        if not isinstance(self.path, str) or not self.path.strip():
            raise ValueError("path must be a non-empty string")

        # Validate relevance_score
        if not isinstance(self.relevance_score, (float, int)):
            raise ValueError("relevance_score must be a float")
        if not 0.0 <= self.relevance_score <= 1.0:
            raise ValueError("relevance_score must be between 0.0 and 1.0")

        # Validate size_tokens
        if not isinstance(self.size_tokens, int) or self.size_tokens < 0:
            raise ValueError("size_tokens must be a non-negative integer")

        # Validate section
        if self.section is not None and not isinstance(self.section, str):
            raise ValueError("section must be a string or None")


class MMRRanker:
    """
    Implements Maximal Marginal Relevance (MMR) ranking for file selection.

    MMR balances relevance and diversity:
    - λ (lambda): Weight for relevance vs diversity (default 0.7)
    - λ = 1.0: Pure relevance (no diversity)
    - λ = 0.5: Equal weight
    - λ = 0.0: Pure diversity (no relevance)

    Formula: score = λ*relevance - (1-λ)*max_similarity_to_selected
    """

    def __init__(self, lambda_param: float = 0.7):
        """
        Initialize MMRRanker.

        Args:
            lambda_param: Trade-off between relevance (1.0) and diversity (0.0)
                         Default 0.7 = 70% relevance, 30% diversity
        """
        if not 0.0 <= lambda_param <= 1.0:
            raise ValueError("lambda_param must be between 0.0 and 1.0")
        self.lambda_param = lambda_param

    def compute_similarity(self, file1: str, file2: str) -> float:
        """
        Calculate Jaccard similarity between two file paths.

        Splits paths into components (directories) and computes:
        similarity = intersection / union

        Examples:
            "tests/auth/test_login.py" vs "tests/auth/test_logout.py" → 0.67
            "src/auth.py" vs "tests/test_auth.py" → 0.0

        Args:
            file1: First file path
            file2: Second file path

        Returns:
            Similarity score (0.0 = completely different, 1.0 = identical)
        """
        # Split paths into components (directories)
        components1 = set(file1.replace('\\', '/').split('/'))
        components2 = set(file2.replace('\\', '/').split('/'))

        # Calculate Jaccard similarity
        intersection = len(components1 & components2)
        union = len(components1 | components2)

        return intersection / union if union != 0 else 0.0

    def rank(self, candidates: List[FileCandidate]) -> List[FileCandidate]:
        """
        Rank files using MMR algorithm.

        Algorithm:
        1. Start with empty selected list
        2. Pick most relevant file first
        3. For each subsequent file:
           - score = λ*relevance - (1-λ)*max_similarity_to_selected
           - Pick highest scoring, add to selected
        4. Repeat until all files ranked

        Args:
            candidates: List of FileCandidate objects to rank

        Returns:
            Sorted list (most diverse + relevant first)

        Example:
            candidates = [
                FileCandidate("tests/auth/test_login.py", 0.9, 500),
                FileCandidate("tests/auth/test_logout.py", 0.85, 450),
                FileCandidate("src/auth.py", 0.8, 1000)
            ]

            ranked = ranker.rank(candidates)
            # Result: [tests/auth/test_login.py, src/auth.py, tests/auth/test_logout.py]
            # (test_logout excluded because too similar to test_login)
        """
        # Edge cases
        if not candidates:
            return []

        if len(candidates) == 1:
            return candidates.copy()

        # Initialize
        selected: List[FileCandidate] = []
        remaining = candidates.copy()

        # Pick most relevant first
        remaining.sort(key=lambda c: c.relevance_score, reverse=True)
        selected.append(remaining.pop(0))

        # Iteratively pick most diverse + relevant
        while remaining:
            max_mmr_score = -float('inf')
            best_candidate = None
            best_idx = -1

            for idx, candidate in enumerate(remaining):
                # Calculate max similarity to already selected files
                max_sim = max(
                    self.compute_similarity(candidate.path, s.path)
                    for s in selected
                )

                # MMR formula: λ*rel - (1-λ)*max_sim
                mmr_score = (
                    self.lambda_param * candidate.relevance_score -
                    (1 - self.lambda_param) * max_sim
                )

                if mmr_score > max_mmr_score:
                    max_mmr_score = mmr_score
                    best_candidate = candidate
                    best_idx = idx

            # Add best to selected, remove from remaining
            if best_candidate:
                selected.append(best_candidate)
                remaining.pop(best_idx)

        return selected


# Unit tests
if __name__ == "__main__":
    import unittest

    class TestMMRRanker(unittest.TestCase):
        def test_basic_functionality(self):
            """Test ranking with simple list of items."""
            ranker = MMRRanker(lambda_param=0.7)
            candidates = [
                FileCandidate("tests/auth/test_login.py", 0.9, 500),
                FileCandidate("tests/auth/test_logout.py", 0.85, 450),
                FileCandidate("src/auth.py", 0.8, 1000)
            ]
            result = ranker.rank(candidates)

            # First should be most relevant
            self.assertEqual(result[0].path, "tests/auth/test_login.py")

            # Should have all 3
            self.assertEqual(len(result), 3)

        def test_empty_list(self):
            """Test ranking with empty list."""
            ranker = MMRRanker()
            result = ranker.rank([])
            self.assertEqual(result, [])

        def test_single_item(self):
            """Test ranking with single item."""
            ranker = MMRRanker()
            candidates = [FileCandidate("test.py", 0.9, 100)]
            result = ranker.rank(candidates)
            self.assertEqual(len(result), 1)
            self.assertEqual(result[0].path, "test.py")

        def test_diversity_enforcement(self):
            """Test that diversity is enforced."""
            ranker = MMRRanker(lambda_param=0.5)  # Equal weight
            candidates = [
                FileCandidate("tests/auth/test_a.py", 0.9, 100),
                FileCandidate("tests/auth/test_b.py", 0.88, 100),
                FileCandidate("tests/auth/test_c.py", 0.86, 100),
                FileCandidate("src/other/file.py", 0.85, 100)  # Different path
            ]
            result = ranker.rank(candidates)

            # src/other/file.py should rank high despite lower relevance
            # because it's diverse
            paths = [c.path for c in result]
            self.assertIn("src/other/file.py", paths[:2])

        def test_similarity_calculation(self):
            """Test path similarity calculation."""
            ranker = MMRRanker()

            # Same directory = high similarity
            sim1 = ranker.compute_similarity(
                "tests/auth/test_login.py",
                "tests/auth/test_logout.py"
            )
            self.assertGreaterEqual(sim1, 0.5)

            # Different directories = low similarity
            sim2 = ranker.compute_similarity(
                "src/auth.py",
                "tests/test_auth.py"
            )
            self.assertLess(sim2, 0.5)

            # Identical = 1.0
            sim3 = ranker.compute_similarity("test.py", "test.py")
            self.assertEqual(sim3, 1.0)

    # Run tests
    unittest.main()
